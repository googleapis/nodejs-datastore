// Copyright 2014 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import * as assert from 'assert';
import {readFileSync} from 'fs';
import * as path from 'path';
import {after, before, describe, it} from 'mocha';
import * as yaml from 'js-yaml';
import {Datastore, Index} from '../src';
import {google} from '../protos/protos';
import {Storage} from '@google-cloud/storage';
import {AggregateField} from '../src/aggregate';
import {entity} from '../src/entity';
import KEY_SYMBOL = entity.KEY_SYMBOL;
import {PropertyFilter, and, or} from '../src/filter';

const SECOND_DATABASE_ID = 'foo2';

describe('Datastore', () => {
  const testKinds: string[] = [];
  const datastore = new Datastore({
    namespace: `${Date.now()}`,
  });
  // Override the Key method so we can track what keys are created during the
  // tests. They are then deleted in the `after` hook.
  const key = datastore.key;
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  datastore.key = function (options: any) {
    const keyObject = key.call(this, options);
    testKinds.push(keyObject.kind);
    return keyObject;
  };

  const {indexes: DECLARED_INDEXES} = yaml.load(
    readFileSync(path.join(__dirname, 'data', 'index.yaml'), 'utf8')
  ) as {indexes: google.datastore.admin.v1.IIndex[]};

  // TODO/DX ensure indexes before testing, and maybe? cleanup indexes after
  //  possible implications with kokoro project

  after(async () => {
    async function deleteEntities(kind: string) {
      const query = datastore.createQuery(kind).select('__key__');
      const [entities] = await datastore.runQuery(query);
      const keys = entities.map(entity => {
        return entity[datastore.KEY];
      });
      await datastore.delete(keys);
    }
    await Promise.all(testKinds.map(kind => deleteEntities(kind)));
  });

  it('should allocate IDs', async () => {
    const keys = await datastore.allocateIds(datastore.key('Kind'), 10);
    assert.ok(keys);
  });

  it('should get the project id', async () => {
    const projectId = await datastore.getProjectId();
    assert.notEqual(projectId, null);
  });

  describe('create, retrieve and delete', () => {
    const post = {
      title: 'How to make the perfect pizza in your grill',
      tags: ['pizza', 'grill'],
      publishedAt: new Date(),
      author: 'Silvano',
      isDraft: false,
      wordCount: 400,
      rating: 5.0,
      likes: null,
      metadata: {
        views: 100,
      },
    };

    it('should excludeFromIndexes correctly', async () => {
      const longString = Buffer.alloc(1501, '.').toString();
      const postKey = datastore.key(['Post', 'post1']);
      const data = {
        longString,
        notMetadata: true,
        longStringArray: [longString],
        metadata: {
          longString,
          otherProperty: 'value',
          obj: {
            longStringArray: [
              {
                longString,
                nestedLongStringArray: [
                  {
                    longString,
                    nestedProperty: true,
                  },
                  {
                    longString,
                  },
                ],
              },
            ],
          },
          longStringArray: [
            {
              longString,
              nestedLongStringArray: [
                {
                  longString,
                  nestedProperty: true,
                },
                {
                  longString,
                },
              ],
            },
          ],
        },
      };

      await datastore.save({
        key: postKey,
        data,
        excludeFromIndexes: [
          'longString',
          'longStringArray[]',
          'metadata.obj.longString',
          'metadata.obj.longStringArray[].longString',
          'metadata.obj.longStringArray[].nestedLongStringArray[].longString',
          'metadata.longString',
          'metadata.longStringArray[].longString',
          'metadata.longStringArray[].nestedLongStringArray[].longString',
        ],
      });
      const [entity] = await datastore.get(postKey);
      assert.deepStrictEqual(entity[datastore.KEY], postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, data);
      await datastore.delete(postKey);
    });

    it('should remove index with using wildcard in excludeFromIndexes', async () => {
      const longString = Buffer.alloc(1501, '.').toString();
      const postKey = datastore.key(['Post', 'post3']);
      const data = {
        longString,
        notMetadata: true,
        longStringArray: [longString],
        metadata: {
          longString,
          otherProperty: 'value',
          obj: {
            longStringArray: [
              {
                longString,
                nestedLongStringArray: [
                  {
                    longString,
                    nestedProperty: true,
                  },
                  {
                    longString,
                  },
                ],
              },
            ],
          },
          longStringArray: [
            {
              longString,
              nestedLongStringArray: [
                {
                  longString,
                  nestedProperty: true,
                },
                {
                  longString,
                },
              ],
            },
          ],
        },
      };

      const excludeFromIndexes = [
        'longString',
        'longStringArray[]',
        'metadata.longString',
        'metadata.obj.*',
        'metadata.longStringArray[].*',
      ];

      await datastore.save({
        key: postKey,
        data,
        excludeFromIndexes,
      });
      const [entity] = await datastore.get(postKey);
      assert.deepStrictEqual(entity[datastore.KEY], postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, data);
      await datastore.delete(postKey);
    });

    it('should auto remove index with excludeLargeProperties enabled', async () => {
      const longString = Buffer.alloc(1501, '.').toString();
      const postKey = datastore.key(['Post', 'post2']);
      const data = {
        longString,
        notMetadata: true,
        longStringArray: [longString],
        metadata: {
          longString,
          otherProperty: 'value',
          obj: {
            longStringArray: [
              {
                longString,
                nestedLongStringArray: [
                  {
                    longString,
                    nestedProperty: true,
                  },
                  {
                    longString,
                  },
                ],
              },
            ],
          },
          longStringArray: [
            {
              longString,
              nestedLongStringArray: [
                {
                  longString,
                  nestedProperty: true,
                },
                {
                  longString,
                },
              ],
            },
          ],
        },
      };

      await datastore.save({
        key: postKey,
        data,
        excludeLargeProperties: true,
      });
      const [entity] = await datastore.get(postKey);
      assert.deepStrictEqual(entity[datastore.KEY], postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, data);
      await datastore.delete(postKey);
    });

    it('should accurately save/get a large int value via Datastore.int()', async () => {
      const postKey = datastore.key('Team');
      const largeIntValueAsString = '9223372036854775807';
      const points = Datastore.int(largeIntValueAsString);
      await datastore.save({key: postKey, data: {points}});
      const [entity] = await datastore.get(postKey, {wrapNumbers: true});
      assert.strictEqual(entity.points.value, largeIntValueAsString);
      assert.throws(() => entity.points.valueOf());
      await datastore.delete(postKey);
    });

    it('should wrap specified properties via IntegerTypeCastOptions.properties', async () => {
      const postKey = datastore.key('Scores');
      const largeIntValueAsString = '9223372036854775807';
      const panthers = Datastore.int(largeIntValueAsString);
      const broncos = 922337203;
      let integerTypeCastFunctionCalled = 0;
      await datastore.save({key: postKey, data: {panthers, broncos}});
      const [entity] = await datastore.get(postKey, {
        wrapNumbers: {
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          integerTypeCastFunction: (value: any) => {
            integerTypeCastFunctionCalled++;
            return value.toString();
          },
          properties: 'panthers',
        },
      });
      // verify that value of property 'panthers' was converted via 'integerTypeCastFunction'.
      assert.strictEqual(entity.panthers, largeIntValueAsString);
      assert.strictEqual(integerTypeCastFunctionCalled, 1);
      // verify that value of the property broncos was converted to int by default logic.
      assert.strictEqual(entity.broncos, broncos);
      await datastore.delete(postKey);
    });

    it('should save/get/delete with a key name', async () => {
      const postKey = datastore.key(['Post', 'post1']);
      await datastore.save({key: postKey, data: post});
      const [entity] = await datastore.get(postKey);
      assert.deepStrictEqual(entity[datastore.KEY], postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, post);
      await datastore.delete(postKey);
    });

    describe('multi-db support for read and write operations', () => {
      it('should run a query with another database', async () => {
        // First verify that a record gets written to datastore
        const postKey = datastore.key(['Post', 'post1']);
        await datastore.save({key: postKey, data: post});
        const query = datastore.createQuery('Post').hasAncestor(postKey);
        const [defaultDatastoreResults] = await datastore.runQuery(query);
        assert.strictEqual(defaultDatastoreResults.length, 1);
        const [entity] = await datastore.get(postKey);
        assert.strictEqual(entity.author, 'Silvano');
        // With another database, verify that a query returns no results
        const otherDatastore = new Datastore({
          namespace: `${Date.now()}`,
          databaseId: SECOND_DATABASE_ID,
        });
        const [secondDatastoreResults] = await otherDatastore.runQuery(query);
        assert.strictEqual(secondDatastoreResults.length, 0);
        const [otherEntity] = await otherDatastore.get(postKey);
        assert(typeof otherEntity === 'undefined');
        // Cleanup
        await datastore.delete(postKey);
      });
      it('should ensure save works with another database', async () => {
        // First verify that the default database is empty
        const postKey = datastore.key(['Post', 'post1']);
        const query = datastore.createQuery('Post').hasAncestor(postKey);
        const [defaultDatastoreResults] = await datastore.runQuery(query);
        assert.strictEqual(defaultDatastoreResults.length, 0);
        const [originalSecondaryResults] = await datastore.runQuery(query);
        assert.strictEqual(originalSecondaryResults.length, 0);
        const [entity] = await datastore.get(postKey);
        assert(typeof entity === 'undefined');
        // With another database, verify that saving to the database works
        const otherDatastore = new Datastore({
          namespace: `${Date.now()}`,
          databaseId: SECOND_DATABASE_ID,
        });
        await otherDatastore.save({key: postKey, data: post});
        const [secondDatastoreResults] = await otherDatastore.runQuery(query);
        assert.strictEqual(secondDatastoreResults.length, 1);
        const [originalResults] = await datastore.runQuery(query);
        assert.strictEqual(originalResults.length, 0);
        const [otherEntity] = await otherDatastore.get(postKey);
        assert.strictEqual(otherEntity.author, 'Silvano');
        // Cleanup
        await otherDatastore.delete(postKey);
      });
      it('should ensure save respects the databaseId parameter per key', async () => {
        // First write entities to the database by specifying the database in the key
        const otherDatastore = new Datastore({
          namespace: `${Date.now()}`,
          databaseId: SECOND_DATABASE_ID,
        });
        const dataD1 = Object.assign({}, post);
        dataD1.author = 'D1';
        const dataS1 = Object.assign({}, post);
        dataS1.author = 'S1';
        const dataS2 = Object.assign({}, post);
        dataS2.author = 'S2';
        const dataS3 = Object.assign({}, post);
        dataS3.author = 'S3';
        const postKeyDefault1 = datastore.key(['Post', 'postD1']);
        const postKeySecondary1 = otherDatastore.key(['Post', 'postS1']);
        const postKeySecondary2 = otherDatastore.key(['Post', 'postS2']);
        const postKeySecondary3 = otherDatastore.key(['Post', 'postS3']);
        await datastore.save({key: postKeyDefault1, data: dataD1});
        await otherDatastore.save({key: postKeySecondary1, data: dataS1});
        await otherDatastore.save({key: postKeySecondary2, data: dataS2});
        await otherDatastore.save({key: postKeySecondary3, data: dataS3});
        // Next, ensure that the default database has the right records
        const query = datastore
          .createQuery('Post')
          .hasAncestor(postKeyDefault1);
        const [defaultDatastoreResults] = await datastore.runQuery(query);
        assert.strictEqual(defaultDatastoreResults.length, 1);
        assert.strictEqual(defaultDatastoreResults[0].author, 'D1');
        // Next, ensure that the other database has the right records
        const queryS1 = otherDatastore
          .createQuery('Post')
          .hasAncestor(postKeySecondary1);
        const [secondDatastoreResults1] = await otherDatastore.runQuery(
          queryS1
        );
        assert.strictEqual(secondDatastoreResults1.length, 1);
        assert.strictEqual(secondDatastoreResults1[0].author, 'S1');
        const queryS2 = otherDatastore
          .createQuery('Post')
          .hasAncestor(postKeySecondary2);
        const [secondDatastoreResults2] = await otherDatastore.runQuery(
          queryS2
        );
        assert.strictEqual(secondDatastoreResults2.length, 1);
        assert.strictEqual(secondDatastoreResults2[0].author, 'S2');
        const queryS3 = otherDatastore
          .createQuery('Post')
          .hasAncestor(postKeySecondary3);
        const [secondDatastoreResults3] = await otherDatastore.runQuery(
          queryS3
        );
        assert.strictEqual(secondDatastoreResults3.length, 1);
        assert.strictEqual(secondDatastoreResults3[0].author, 'S3');
        // Cleanup
        await datastore.delete(postKeyDefault1);
        await otherDatastore.delete(postKeySecondary1);
        await otherDatastore.delete(postKeySecondary2);
        await otherDatastore.delete(postKeySecondary3);
      });
    });

    it('should save/get/delete from a snapshot', async () => {
      function sleep(ms: number) {
        return new Promise(resolve => setTimeout(resolve, ms));
      }
      const post2 = {
        title: 'Another way to make pizza',
        tags: ['pizza', 'grill'],
        publishedAt: new Date(),
        author: 'Silvano',
        isDraft: false,
        wordCount: 400,
        rating: 5.0,
        likes: null,
        metadata: {
          views: 100,
        },
      };
      const path = ['Post', 'post1'];
      const postKey = datastore.key(path);
      await datastore.save({key: postKey, data: post});
      await sleep(1000);
      const savedTime = Date.now();
      await sleep(1000);
      // Save new post2 data, but then verify the timestamp read has post1 data
      await datastore.save({key: postKey, data: post2});
      const [entity] = await datastore.get(postKey, {readTime: savedTime});
      assert.deepStrictEqual(entity[datastore.KEY], postKey);
      const [entityNoOptions] = await datastore.get(postKey);
      assert.deepStrictEqual(entityNoOptions[datastore.KEY], postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, post);
      delete entityNoOptions[datastore.KEY];
      assert.deepStrictEqual(entityNoOptions, post2);
      await datastore.delete(postKey);
    });

    it('should save/get/delete with a numeric key id', async () => {
      const postKey = datastore.key(['Post', 123456789]);
      await datastore.save({key: postKey, data: post});
      const [entity] = await datastore.get(postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, post);
      await datastore.delete(postKey);
    });

    it('should save/get/delete a buffer', async () => {
      const postKey = datastore.key(['Post']);
      const data = {
        buf: Buffer.from('010100000000000000000059400000000000006940', 'hex'),
      };
      await datastore.save({key: postKey, data});
      const assignedId = postKey.id;
      assert(assignedId);
      const [entity] = await datastore.get(postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, data);
      await datastore.delete(datastore.key(['Post', assignedId as string]));
    });

    it('should save/get/delete an empty buffer', async () => {
      const postKey = datastore.key(['Post']);
      const data = {
        buf: Buffer.from([]),
      };
      await datastore.save({key: postKey, data});
      const assignedId = postKey.id;
      assert(assignedId);
      const [entity] = await datastore.get(postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, data);
      await datastore.delete(datastore.key(['Post', assignedId as string]));
    });

    it('should save/get/delete with a generated key id', async () => {
      const postKey = datastore.key('Post');
      await datastore.save({key: postKey, data: post});

      // The key's path should now be complete.
      assert(postKey.id);

      const [entity] = await datastore.get(postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, post);
      await datastore.delete(postKey);
    });

    it('should save/get/update', async () => {
      const postKey = datastore.key('Post');
      await datastore.save({key: postKey, data: post});
      const [entity] = await datastore.get(postKey);
      assert.strictEqual(entity.title, post.title);
      entity.title = 'Updated';
      await datastore.save(entity);
      const [entity2] = await datastore.get(postKey);
      assert.strictEqual(entity2.title, 'Updated');
      await datastore.delete(postKey);
    });

    it('should save/get/merge', async () => {
      const postKey = datastore.key(['Post', 1]);
      const originalData = {
        key: postKey,
        data: {
          title: 'Original',
          status: 'neat',
        },
      };
      await datastore.save(originalData);
      const updatedData = {
        key: postKey,
        data: {
          title: 'Updated',
        },
      };
      await datastore.merge(updatedData);
      const [entity] = await datastore.get(postKey);
      assert.strictEqual(entity.title, updatedData.data.title);
      assert.strictEqual(entity.status, originalData.data.status);
      await datastore.delete(postKey);
    });

    it('should save and get with a string ID', async () => {
      const longIdKey = datastore.key([
        'Post',
        datastore.int('100000000000001234'),
      ]);
      await datastore.save({
        key: longIdKey,
        data: {
          test: true,
        },
      });
      const [entity] = await datastore.get(longIdKey);
      assert.strictEqual(entity.test, true);
    });

    it('should fail explicitly set second insert on save', async () => {
      const postKey = datastore.key('Post');
      await datastore.save({key: postKey, data: post});

      // The key's path should now be complete.
      assert(postKey.id);
      await assert.rejects(
        datastore.save({
          key: postKey,
          method: 'insert',
          data: post,
        })
      );
      const [entity] = await datastore.get(postKey);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, post);
      await datastore.delete(postKey);
    });

    it('should fail explicitly set first update on save', async () => {
      const postKey = datastore.key('Post');
      await assert.rejects(
        datastore.save({
          key: postKey,
          method: 'update',
          data: post,
        })
      );
    });

    it('should save/get/delete multiple entities at once', async () => {
      const post2 = {
        title: 'How to make the perfect homemade pasta',
        tags: ['pasta', 'homemade'],
        publishedAt: new Date('2001-01-01T00:00:00.000Z'),
        author: 'Silvano',
        isDraft: false,
        wordCount: 450,
        rating: 4.5,
      };
      const key1 = datastore.key('Post');
      const key2 = datastore.key('Post');
      await datastore.save([
        {key: key1, data: post},
        {key: key2, data: post2},
      ]);
      const [entities] = await datastore.get([key1, key2]);
      assert.strictEqual(entities.length, 2);
      await datastore.delete([key1, key2]);
    });

    it('should get multiple entities in a stream', done => {
      const key1 = datastore.key('Post');
      const key2 = datastore.key('Post');

      datastore.save(
        [
          {key: key1, data: post},
          {key: key2, data: post},
        ],
        err => {
          assert.ifError(err);

          let numEntitiesEmitted = 0;

          datastore
            .createReadStream([key1, key2])
            .on('error', done)
            .on('data', () => {
              numEntitiesEmitted++;
            })
            .on('end', () => {
              assert.strictEqual(numEntitiesEmitted, 2);
              datastore.delete([key1, key2], done);
            });
        }
      );
    });

    it('should save keys as a part of entity and query by key', async () => {
      const personKey = datastore.key(['People', 'US', 'Person', 'name']);
      await datastore.save({
        key: personKey,
        data: {
          fullName: 'Full name',
          linkedTo: personKey, // himself
        },
      });
      const query = datastore
        .createQuery('Person')
        .hasAncestor(datastore.key(['People', 'US']))
        .filter('linkedTo', personKey);
      const [results] = await datastore.runQuery(query);
      assert.strictEqual(results![0].fullName, 'Full name');
      assert.deepStrictEqual(results![0].linkedTo, personKey);
      await datastore.delete(personKey);
    });

    it('should save with an empty buffer', async () => {
      const key = datastore.key(['TEST']);
      const result = await datastore.save({
        key: key,
        data: {
          name: 'test',
          blob: Buffer.from([]),
        },
      });
      const mutationResult = result.pop()?.mutationResults?.pop();
      assert.strictEqual(mutationResult?.key?.path?.pop()?.kind, 'TEST');
    });

    describe('entity types', () => {
      it('should save and decode an int', async () => {
        const integerValue = 2015;
        const integerType = Datastore.int(integerValue);
        const key = datastore.key('Person');
        await datastore.save({
          key,
          data: {
            year: integerType,
          },
        });
        const [entity] = await datastore.get(key);
        assert.strictEqual(entity.year, integerValue);
      });

      it('should save and decode a double', async () => {
        const doubleValue = 99.99;
        const doubleType = Datastore.double(doubleValue);
        const key = datastore.key('Person');
        await datastore.save({
          key,
          data: {
            nines: doubleType,
          },
        });
        const [entity] = await datastore.get(key);
        assert.strictEqual(entity.nines, doubleValue);
      });

      it('should save and decode a geo point', async () => {
        const geoPointValue = {
          latitude: 40.6894,
          longitude: -74.0447,
        };
        const geoPointType = Datastore.geoPoint(geoPointValue);
        const key = datastore.key('Person');
        await datastore.save({
          key,
          data: {
            location: geoPointType,
          },
        });
        const [entity] = await datastore.get(key);
        assert.deepStrictEqual(entity.location, geoPointValue);
      });
    });
  });

  describe('querying the datastore', () => {
    const ancestor = datastore.key(['Book', 'GoT']);

    const keys = [
      // Paths:
      ['Rickard'],
      ['Rickard', 'Character', 'Eddard'],
      ['Catelyn'],
      ['Rickard', 'Character', 'Eddard', 'Character', 'Arya'],
      ['Rickard', 'Character', 'Eddard', 'Character', 'Sansa'],
      ['Rickard', 'Character', 'Eddard', 'Character', 'Robb'],
      ['Rickard', 'Character', 'Eddard', 'Character', 'Bran'],
      ['Rickard', 'Character', 'Eddard', 'Character', 'Jon Snow'],
    ].map(path => {
      return datastore.key(['Book', 'GoT', 'Character'].concat(path));
    });

    const characters = [
      {
        name: 'Rickard',
        family: 'Stark',
        appearances: 9,
        alive: false,
      },
      {
        name: 'Eddard',
        family: 'Stark',
        appearances: 9,
        alive: false,
      },
      {
        name: 'Catelyn',
        family: ['Stark', 'Tully'],
        appearances: 26,
        alive: false,
      },
      {
        name: 'Arya',
        family: 'Stark',
        appearances: 33,
        alive: true,
      },
      {
        name: 'Sansa',
        family: 'Stark',
        appearances: 31,
        alive: true,
      },
      {
        name: 'Robb',
        family: 'Stark',
        appearances: 22,
        alive: false,
      },
      {
        name: 'Bran',
        family: 'Stark',
        appearances: 25,
        alive: true,
      },
      {
        name: 'Jon Snow',
        family: 'Stark',
        appearances: 32,
        alive: true,
      },
    ];

    before(async () => {
      const keysToSave = keys.map((key, index) => {
        return {
          key,
          data: characters[index],
        };
      });
      await datastore.save(keysToSave);
    });

    after(async () => {
      await datastore.delete(keys);
    });

    it('should limit queries', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .limit(5);
      const [firstEntities, info] = await datastore.runQuery(q);
      assert.strictEqual(firstEntities!.length, 5);
      const secondQ = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .start(info!.endCursor!);
      const [secondEntities] = await datastore.runQuery(secondQ);
      assert.strictEqual(secondEntities!.length, 3);
    });

    it('should not go over a limit', async () => {
      const limit = 3;
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .limit(limit);
      const [results] = await datastore.runQuery(q);
      assert.strictEqual(results!.length, limit);
    });

    it('should run a query as a stream', done => {
      const q = datastore.createQuery('Character').hasAncestor(ancestor);
      let resultsReturned = 0;
      datastore
        .runQueryStream(q)
        .on('error', done)
        .on('data', () => resultsReturned++)
        .on('end', () => {
          assert.strictEqual(resultsReturned, characters.length);
          done();
        });
    });

    it('should run a datastore query as a stream via query#runStream', done => {
      const q = datastore.createQuery('Character').hasAncestor(ancestor);
      let resultsReturned = 0;
      q.runStream()
        .on('error', done)
        .on('data', () => resultsReturned++)
        .on('end', () => {
          assert.strictEqual(resultsReturned, characters.length);
          done();
        });
    });

    it('should run a transaction query as a stream via query#runStream', done => {
      const transaction = datastore.transaction();
      const q = transaction.createQuery('Character').hasAncestor(ancestor);
      let resultsReturned = 0;
      q.runStream()
        .on('error', done)
        .on('data', () => resultsReturned++)
        .on('end', () => {
          assert.strictEqual(resultsReturned, characters.length);
          done();
        });
    });

    it('should not go over a limit with a stream', done => {
      const limit = 3;
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .limit(limit);
      let resultsReturned = 0;
      datastore
        .runQueryStream(q)
        .on('error', done)
        .on('data', () => resultsReturned++)
        .on('end', () => {
          assert.strictEqual(resultsReturned, limit);
          done();
        });
    });

    it('should filter queries with simple indexes', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .filter('appearances', '>=', 20);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 6);
    });

    it('should filter queries with NOT_EQUAL', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .filter('appearances', '!=', 9);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 6);
    });

    it('should filter queries with IN', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .filter('appearances', 'IN', [9, 25]);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 3);
    });

    it('should filter queries with __key__ and IN', async () => {
      const key1 = datastore.key(['Book', 'GoT', 'Character', 'Rickard']);
      const key2 = datastore.key([
        'Book',
        'GoT',
        'Character',
        'Rickard',
        'Character',
        'Eddard',
        'Character',
        'Sansa',
      ]);
      const key3 = datastore.key([
        'Book',
        'GoT',
        'Character',
        'Rickard',
        'Character',
        'Eddard',
      ]);
      const value = [key1, key2, key3];
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .filter('__key__', 'IN', value);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 3);
      assert.deepStrictEqual(entities[0][KEY_SYMBOL], key1);
      assert.deepStrictEqual(entities[1][KEY_SYMBOL], key3);
      assert.deepStrictEqual(entities[2][KEY_SYMBOL], key2);
    });

    it('should filter queries with NOT_IN', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .filter('appearances', 'NOT_IN', [9, 25]);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 5);
    });

    it('should filter queries with defined indexes', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .filter('family', 'Stark')
        .filter('appearances', '>=', 20);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 6);
    });
    describe('with the filter function using the Filter class', () => {
      it('should run a query with one property filter', async () => {
        const filter = new PropertyFilter('family', '=', 'Stark');
        const q = datastore
          .createQuery('Character')
          .filter(filter)
          .hasAncestor(ancestor);
        const [entities] = await datastore.runQuery(q);
        assert.strictEqual(entities!.length, 8);
      });
      it('should run a query with two property filters', async () => {
        const q = datastore
          .createQuery('Character')
          .filter(new PropertyFilter('family', '=', 'Stark'))
          .filter(new PropertyFilter('appearances', '>=', 20));
        const [entities] = await datastore.runQuery(q);
        assert.strictEqual(entities!.length, 6);
      });
      it('should run a query using new Filter class with filter', async () => {
        const q = datastore
          .createQuery('Character')
          .filter('family', 'Stark')
          .filter(new PropertyFilter('appearances', '>=', 20));
        const [entities] = await datastore.runQuery(q);
        assert.strictEqual(entities!.length, 6);
        for (const entity of entities) {
          if (Array.isArray(entity.family)) {
            assert.strictEqual(entity.family[0], 'Stark');
          } else {
            assert.strictEqual(entity.family, 'Stark');
          }
          assert(entity.appearances >= 20);
        }
      });
      it('should run a query using an AND composite filter', async () => {
        const q = datastore
          .createQuery('Character')
          .filter(
            and([
              new PropertyFilter('family', '=', 'Stark'),
              new PropertyFilter('appearances', '>=', 20),
            ])
          );
        const [entities] = await datastore.runQuery(q);
        assert.strictEqual(entities!.length, 6);
        for (const entity of entities) {
          if (Array.isArray(entity.family)) {
            assert.strictEqual(entity.family[0], 'Stark');
          } else {
            assert.strictEqual(entity.family, 'Stark');
          }
          assert(entity.appearances >= 20);
        }
      });
      it('should run a query using an OR composite filter', async () => {
        const q = datastore
          .createQuery('Character')
          .filter(
            or([
              new PropertyFilter('family', '=', 'Stark'),
              new PropertyFilter('appearances', '>=', 20),
            ])
          );
        const [entities] = await datastore.runQuery(q);
        assert.strictEqual(entities!.length, 8);
        let atLeastOne = false;
        for (const entity of entities) {
          const familyHasStark = Array.isArray(entity.family)
            ? entity.family[0] === 'Stark'
            : entity.family === 'Stark';
          const hasEnoughAppearances = entity.appearances >= 20;
          if (familyHasStark && !hasEnoughAppearances) {
            atLeastOne = true;
          }
        }
        assert(atLeastOne);
      });
      describe('using hasAncestor and Filter class', () => {
        const secondAncestor = datastore.key([
          'Book',
          'GoT',
          'Character',
          'Rickard',
          'Character',
          'Eddard',
        ]);
        it('should run a query using hasAncestor last', async () => {
          const q = datastore
            .createQuery('Character')
            .filter(new PropertyFilter('appearances', '<', 30))
            .hasAncestor(secondAncestor);
          const [entities] = await datastore.runQuery(q);
          assert.strictEqual(entities!.length, 3);
        });
        it('should run a query using hasAncestor first', async () => {
          const q = datastore
            .createQuery('Character')
            .hasAncestor(secondAncestor)
            .filter(new PropertyFilter('appearances', '<', 30));
          const [entities] = await datastore.runQuery(q);
          assert.strictEqual(entities!.length, 3);
        });
      });
    });
    describe('with a count filter', () => {
      it('should run a count aggregation', async () => {
        const q = datastore.createQuery('Character');
        const aggregate = datastore
          .createAggregationQuery(q)
          .addAggregation(AggregateField.count());
        const [results] = await datastore.runAggregationQuery(aggregate);
        assert.deepStrictEqual(results, [{property_1: 8}]);
      });
      it('should run a count aggregation with a list of aggregates', async () => {
        const q = datastore.createQuery('Character');
        const aggregate = datastore
          .createAggregationQuery(q)
          .addAggregations([AggregateField.count(), AggregateField.count()]);
        const [results] = await datastore.runAggregationQuery(aggregate);
        assert.deepStrictEqual(results, [{property_1: 8, property_2: 8}]);
      });
      it('should run a count aggregation having other filters', async () => {
        const q = datastore
          .createQuery('Character')
          .filter('family', 'Stark')
          .filter('appearances', '>=', 20);
        const aggregate = datastore
          .createAggregationQuery(q)
          .addAggregation(AggregateField.count().alias('total'));
        const [results] = await datastore.runAggregationQuery(aggregate);
        assert.deepStrictEqual(results, [{total: 6}]);
      });
      it('should run a count aggregate filter with an alias', async () => {
        const q = datastore.createQuery('Character');
        const aggregate = datastore
          .createAggregationQuery(q)
          .addAggregation(AggregateField.count().alias('total'));
        const [results] = await datastore.runAggregationQuery(aggregate);
        assert.deepStrictEqual(results, [{total: 8}]);
      });
      it('should do multiple count aggregations with aliases', async () => {
        const q = datastore.createQuery('Character');
        const aggregate = datastore
          .createAggregationQuery(q)
          .addAggregations([
            AggregateField.count().alias('total'),
            AggregateField.count().alias('total2'),
          ]);
        const [results] = await datastore.runAggregationQuery(aggregate);
        assert.deepStrictEqual(results, [{total: 8, total2: 8}]);
      });
      it('should run a count aggregation filter with a limit', async () => {
        const q = datastore.createQuery('Character').limit(5);
        const aggregate = datastore
          .createAggregationQuery(q)
          .addAggregation(AggregateField.count());
        const [results] = await datastore.runAggregationQuery(aggregate);
        assert.deepStrictEqual(results, [{property_1: 5}]);
      });
      it('should run a count aggregate filter with a limit and an alias', async () => {
        const q = datastore.createQuery('Character').limit(7);
        const aggregate = datastore
          .createAggregationQuery(q)
          .addAggregations([AggregateField.count().alias('total')]);
        const [results] = await datastore.runAggregationQuery(aggregate);
        assert.deepStrictEqual(results, [{total: 7}]);
      });
    });
    it('should filter by ancestor', async () => {
      const q = datastore.createQuery('Character').hasAncestor(ancestor);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities.length, characters.length);
    });

    it('should construct filters by null status', async () => {
      assert.strictEqual(
        datastore.createQuery('Character').filter('status', null).filters.pop()
          ?.val,
        null
      );
      assert.strictEqual(
        datastore
          .createQuery('Character')
          .filter('status', '=', null)
          .filters.pop()?.val,
        null
      );
    });
    it('should filter by key', async () => {
      const key = datastore.key(['Book', 'GoT', 'Character', 'Rickard']);
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .filter('__key__', key);
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 1);
    });

    it('should order queries', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .order('appearances');

      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities![0].name, characters[0].name);
      assert.strictEqual(entities![7].name, characters[3].name);
    });

    it('should select projections', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .select(['name', 'family']);

      const [entities] = await datastore.runQuery(q);
      delete entities[0][datastore.KEY];
      assert.deepStrictEqual(entities![0], {
        name: 'Arya',
        family: 'Stark',
      });
      delete entities[8][datastore.KEY];
      assert.deepStrictEqual(entities![8], {
        name: 'Sansa',
        family: 'Stark',
      });
    });

    it('should paginate with offset and limit', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .offset(2)
        .limit(3)
        .order('appearances');

      const [entities, info] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, 3);
      assert.strictEqual(entities![0].name, 'Robb');
      assert.strictEqual(entities![2].name, 'Catelyn');
      const secondQ = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .order('appearances')
        .start(info!.endCursor!);
      const [secondEntities] = await datastore.runQuery(secondQ);
      assert.strictEqual(secondEntities!.length, 3);
      assert.strictEqual(secondEntities![0].name, 'Sansa');
      assert.strictEqual(secondEntities![2].name, 'Arya');
    });

    it('should resume from a start cursor', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .offset(2)
        .limit(2)
        .order('appearances');
      const [, info] = await datastore.runQuery(q);
      const secondQ = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .order('appearances')
        .start(info!.endCursor!);
      const [secondEntities] = await datastore.runQuery(secondQ);
      assert.strictEqual(secondEntities!.length, 4);
      assert.strictEqual(secondEntities![0].name, 'Catelyn');
      assert.strictEqual(secondEntities![3].name, 'Arya');
    });

    it('should group queries', async () => {
      const q = datastore
        .createQuery('Character')
        .hasAncestor(ancestor)
        .groupBy('appearances');
      const [entities] = await datastore.runQuery(q);
      assert.strictEqual(entities!.length, characters.length - 1);
    });

    it('should query from the Query object', async () => {
      await datastore.createQuery('Character').run();
    });
  });

  describe('transactions', () => {
    it('should run in a transaction', async () => {
      const key = datastore.key(['Company', 'Google']);
      const obj = {
        url: 'www.google.com',
      };
      const transaction = datastore.transaction();
      await transaction.run();
      await transaction.get(key);
      transaction.save({key, data: obj});
      await transaction.commit();
      const [entity] = await datastore.get(key);
      delete entity[datastore.KEY];
      assert.deepStrictEqual(entity, obj);
    });

    it('should commit all saves and deletes at the end', async () => {
      const deleteKey = datastore.key(['Company', 'Subway']);
      const key = datastore.key(['Company', 'Google']);
      const incompleteKey = datastore.key('Company');

      await datastore.save({
        key: deleteKey,
        data: {},
      });
      const transaction = datastore.transaction();

      await transaction.run();
      transaction.delete(deleteKey);

      transaction.save([
        {
          key,
          data: {rating: 10},
        },
        {
          key: incompleteKey,
          data: {rating: 100},
        },
      ]);

      await transaction.commit();

      // Incomplete key should have been given an ID.
      assert.strictEqual(incompleteKey.path.length, 2);

      const [[deletedEntity], [fetchedEntity]] = await Promise.all([
        // Deletes the key that is in the deletion queue.
        datastore.get(deleteKey),
        // Updates data on the key.
        datastore.get(key),
      ]);
      assert.strictEqual(typeof deletedEntity, 'undefined');
      assert.strictEqual(fetchedEntity.rating, 10);
    });

    it('should use the last modification to a key', async () => {
      const incompleteKey = datastore.key('Company');
      const key = datastore.key(['Company', 'Google']);
      const transaction = datastore.transaction();
      await transaction.run();
      transaction.save([
        {
          key,
          data: {
            rating: 10,
          },
        },
        {
          key: incompleteKey,
          data: {
            rating: 100,
          },
        },
      ]);
      transaction.delete(key);
      await transaction.commit();

      // Should not return a result.
      const [entity] = await datastore.get(key);
      assert.strictEqual(entity, undefined);

      // Incomplete key should have been given an id.
      assert.strictEqual(incompleteKey.path.length, 2);
    });

    it('should query within a transaction', async () => {
      const transaction = datastore.transaction();
      await transaction.run();
      const query = transaction.createQuery('Company');
      let entities;
      try {
        [entities] = await query.run();
      } catch (e) {
        await transaction.rollback();
        return;
      }
      assert(entities!.length > 0);
      await transaction.commit();
    });

    it('should aggregate query within a transaction', async () => {
      const transaction = datastore.transaction();
      await transaction.run();
      const query = transaction.createQuery('Company');
      const aggregateQuery = transaction
        .createAggregationQuery(query)
        .count('total');
      let result;
      try {
        [result] = await aggregateQuery.run();
      } catch (e) {
        await transaction.rollback();
        return;
      }
      assert.deepStrictEqual(result, [{total: 2}]);
      await transaction.commit();
    });

    it('should read in a readOnly transaction', async () => {
      const transaction = datastore.transaction({readOnly: true});
      const key = datastore.key(['Company', 'Google']);
      await transaction.run();
      await transaction.get(key);
    });

    it('should not write in a readOnly transaction', async () => {
      const transaction = datastore.transaction({readOnly: true});
      const key = datastore.key(['Company', 'Google']);
      await transaction.run();
      await transaction.get(key);
      transaction.save({key, data: {}});
      await assert.rejects(transaction.commit());
    });
  });

  describe('indexes', () => {
    // @TODO: Until the protos support creating indexes, these tests depend on
    // the remote state of declared indexes. Could be flaky!
    it('should get all indexes', async () => {
      const [indexes] = await datastore.getIndexes();
      assert.ok(
        indexes.length >= DECLARED_INDEXES.length,
        'has at least the number of indexes per system-test/data/index.yaml'
      );

      // Comparing index.yaml and the actual defined index in Datastore requires
      // assumptions to complete a shape transformation, so let's just see if
      // a returned index has the right shape and not inspect the values.
      const [firstIndex] = indexes;

      assert.ok(firstIndex, 'first index is readable');
      assert.ok(firstIndex.metadata!.properties, 'has properties collection');
      assert.ok(
        firstIndex.metadata!.properties.length,
        'with properties inside'
      );
      assert.ok(firstIndex.metadata!.ancestor, 'has the ancestor property');
    });

    it('should get all indexes as a stream', done => {
      const indexes: Index[] = [];

      datastore
        .getIndexesStream()
        .on('error', done)
        .on('data', index => {
          indexes.push(index);
        })
        .on('end', () => {
          assert(indexes.length >= DECLARED_INDEXES.length);
          done();
        });
    });

    it('should get a specific index', async () => {
      const [indexes] = await datastore.getIndexes();
      const [firstIndex] = indexes;

      const index = datastore.index(firstIndex.id);
      const [metadata] = await index.getMetadata();
      assert.deepStrictEqual(
        metadata,
        firstIndex.metadata,
        'asked index is the same as received index'
      );
    });
  });

  describe('importing and exporting entities', () => {
    const gcs = new Storage();
    const bucket = gcs.bucket('nodejs-datastore-system-tests');

    const delay = async (test: Mocha.Context) => {
      const retries = test.currentRetry();
      if (retries === 0) return; // no retry on the first failure.
      // see: https://cloud.google.com/storage/docs/exponential-backoff:
      const ms = Math.pow(2, retries) * 500 + Math.random() * 1000;
      return new Promise(done => {
        console.info(`retrying "${test.title}" in ${ms}ms`);
        setTimeout(done, ms);
      });
    };

    it('should export, then import entities', async function () {
      this.retries(3);
      delay(this);
      const [exportOperation] = await datastore.export({bucket});
      await exportOperation.promise();

      const [files] = await bucket.getFiles({maxResults: 1});
      const [exportedFile] = files;
      assert.ok(exportedFile.name.includes('overall_export_metadata'));

      const [importOperation] = await datastore.import({
        file: exportedFile,
      });

      // This is a >20 minute operation, so we're just going to make sure the
      // right type of operation was started.
      assert.strictEqual(
        (
          importOperation.metadata as google.datastore.admin.v1.IImportEntitiesMetadata
        ).inputUrl,
        `gs://${exportedFile.bucket.name}/${exportedFile.name}`
      );

      await importOperation.cancel();
    });
  });
});
